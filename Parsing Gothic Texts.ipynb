{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project: Tokenizing and Annotating Gothic Texts\n",
    "    Course:   DS 5001\n",
    "    Author:   Elizabeth Burrell\n",
    "    Date:     April 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import re\n",
    "import nltk\n",
    "import plotly_express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_files = r\"C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['book_id','chap_num','para_num', 'sent_num', 'token_num']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "\n",
    "class TextParser():\n",
    "    \"\"\"\n",
    "    A class to parse a single Gutenberg-type text file into a TOKENS dataframe with\n",
    "    an OHCO index. Also has methods to extract a VOCAB table, although vocabulary\n",
    "    tables ought to be generated at the corpus level.\n",
    "    \n",
    "    Sample parameter values:\n",
    "\n",
    "    ohco_pats = [\n",
    "        ('chapter', r\"^\\s*(chapter|letter)\\s+(\\d+)\", 'm')    \n",
    "    ]\n",
    "\n",
    "    clip_pats = [\n",
    "        r'START OF GUTENBERG PROJECT', \n",
    "        r'^\\s*THE END'\n",
    "    ]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    # TODO: Make these private\n",
    "    src_imported:bool = False       \n",
    "    src_clipped:bool = False\n",
    "    src_col_suffix:str ='_str'\n",
    "\n",
    "    join_pat:str = r'\\n'\n",
    "    strip_hyphens:bool = False\n",
    "    strip_whitespace:bool = False\n",
    "    verbose:bool = False\n",
    "\n",
    "    stanford_pos_model:str = \"english-bidirectional-distsim.tagger\"\n",
    "    stanford_pos_model_path = None\n",
    "        \n",
    "    # We assume all OHCOs have sentences and tokens\n",
    "    # and that there are terminal in the list.\n",
    "    ohco_pats:[] = [\n",
    "        ('para', r\"\\n\\n\", 'd'),\n",
    "        ('sent', r\"[.?!;:]+\", 'd'),\n",
    "        ('token', r\"[\\s',-]+\", 'd')\n",
    "    ]\n",
    "        \n",
    "    _ohco_type:{} = {\n",
    "        'd': '_num',\n",
    "        'm': '_id'\n",
    "    }\n",
    "        \n",
    "    def __init__(self, src_file:str, ohco_pats:[], clip_pats:[], use_nltk=True):\n",
    "        \"\"\"Initialize the object and extract config info. If using NLTK, download resources.\"\"\"\n",
    "        self.src_file = src_file            \n",
    "        self.clip_pats = clip_pats # TODO: Validate\n",
    "        self.ohco_pats = ohco_pats + self.ohco_pats # TODO: Validate\n",
    "        self.OHCO = [item[0]+self._ohco_type[item[2]] for item in self.ohco_pats]\n",
    "        self.ohco_names = [item[0] for item in self.ohco_pats]\n",
    "        self.use_nltk = use_nltk\n",
    "\n",
    "        if self.use_nltk:\n",
    "            # Override the last two OHCO items\n",
    "            self.ohco_pats[-2] = ('sent', None, 'nltk')\n",
    "            self.ohco_pats[-1] = ('token', None, 'nltk')\n",
    "            # Make sure you have the NLTK stuff\n",
    "            for package in [\n",
    "                'tokenizers/punkt', \n",
    "                'taggers/averaged_perceptron_tagger', \n",
    "                'corpora/stopwords', \n",
    "                'help/tagsets'\n",
    "            ]:\n",
    "                if self.verbose: print(\"Checking\", package)\n",
    "                try:\n",
    "                    nltk.data.find(package)\n",
    "                except IndexError:\n",
    "                    nltk.download(package)\n",
    "            \n",
    "    def import_source(self, strip:bool=True, char_encoding:str=\"utf-8-sig\"):\n",
    "        \"\"\"Convert a raw text file into a dataframe of lines.\"\"\"\n",
    "        if self.verbose: print(\"Importing \", self.src_file)\n",
    "        text_lines = open(self.src_file,'r', encoding=char_encoding).readlines()\n",
    "        self.LINES = pd.DataFrame({'line_str':text_lines})\n",
    "        self.LINES.index.name = 'line_id'\n",
    "        if strip:\n",
    "            self.LINES.line_str = self.LINES.line_str.str.strip()\n",
    "        self.src_imported = True\n",
    "        if self.verbose: print(\"Clipping text\")\n",
    "        self._clip_lines()\n",
    "        return self        \n",
    "\n",
    "    def _clip_lines(self):\n",
    "        \"\"\"Remove cruft lines from beginning and/or end of file.\"\"\"\n",
    "        start_pat = self.clip_pats[0]\n",
    "        end_pat = self.clip_pats[1]\n",
    "        start = self.LINES.line_str.str.contains(start_pat, regex=True)\n",
    "        end = self.LINES.line_str.str.contains(end_pat, regex=True)\n",
    "        try:\n",
    "            start_line_num = self.LINES.loc[start].index[0]\n",
    "        except IndexError:\n",
    "            raise ValueError(\"Clip start pattern not found.\")            \n",
    "        try:\n",
    "            end_line_num = self.LINES.loc[end].index[0]\n",
    "        except IndexError:\n",
    "            raise ValueError(\"Clip end pattern not found.\")\n",
    "        self.LINES = self.LINES.loc[start_line_num + 1 : end_line_num - 2]\n",
    "        self.src_clipped == True\n",
    "        \n",
    "    def parse_tokens(self):\n",
    "        \"\"\"Convert lines to tokens based on OHCO.\"\"\"\n",
    "        if self.src_imported:\n",
    "\n",
    "            # Start with the LINES df\n",
    "            self.TOKENS = self.LINES.copy()\n",
    "\n",
    "            # Walk through each level of the OHCO to build out TOKENS\n",
    "            for i, level in enumerate(self.OHCO):\n",
    "\n",
    "                if self.verbose: print(f\"Parsing OHCO level {i} {level}\", end=' ')\n",
    "\n",
    "                # Define level-specific variables\n",
    "                parse_type = self.ohco_pats[i][2]\n",
    "                div_name = self.ohco_pats[i][0]\n",
    "                div_pat = self.ohco_pats[i][1]\n",
    "                if i == 0:\n",
    "                    src_div_name = 'line'\n",
    "                else:\n",
    "                    src_div_name = self.ohco_names[i - 1] \n",
    "                src_col = f\"{src_div_name}{self.src_col_suffix}\"\n",
    "                dst_col = f\"{div_name}{self.src_col_suffix}\"\n",
    "\n",
    "                # By Milestone\n",
    "                if parse_type == 'm':\n",
    "                    if self.verbose: print(f\"by milestone {div_pat}\")\n",
    "                    div_lines = self.TOKENS[src_col].str.contains(div_pat, regex=True, case=True) # TODO: Parametize case\n",
    "                    self.TOKENS.loc[div_lines, div_name] = [i+1 for i in range(self.TOKENS.loc[div_lines].shape[0])]\n",
    "                    self.TOKENS[div_name] = self.TOKENS[div_name].ffill()\n",
    "                    self.TOKENS = self.TOKENS.loc[~self.TOKENS[div_name].isna()] \n",
    "                    self.TOKENS = self.TOKENS.loc[~div_lines] \n",
    "                    self.TOKENS[div_name] = self.TOKENS[div_name].astype('int')\n",
    "                    self.TOKENS = self.TOKENS.groupby(self.ohco_names[:i+1], group_keys=True)[src_col]\\\n",
    "                        .apply(lambda x: '\\n'.join(x)).to_frame(dst_col)\n",
    "\n",
    "                    # print(self.TOKENS[dst_col].str.count(r'\\n\\n'))\n",
    "                    print(src_col, dst_col)\n",
    "                    print(self.TOKENS.columns)\n",
    "\n",
    "\n",
    "                # By Delimitter\n",
    "                elif parse_type == 'd':\n",
    "                    if self.verbose: print(f\"by delimitter {div_pat}\")\n",
    "                    self.TOKENS = self.TOKENS[src_col].str.split(div_pat, expand=True).stack().to_frame(dst_col)\n",
    "                \n",
    "                # By NLTK \n",
    "                elif parse_type == 'nltk':\n",
    "                    if self.verbose: print(f\"by NLTK model\")\n",
    "\n",
    "                    if level == 'sent_num':\n",
    "                        self.TOKENS = self.TOKENS.para_str\\\n",
    "                                .apply(lambda x: pd.Series(nltk.sent_tokenize(x), dtype=str))\\\n",
    "                                .stack()\\\n",
    "                                .to_frame('sent_str')\n",
    "                    \n",
    "                    if level == 'token_num':\n",
    "                        if self.strip_hyphens == True:\n",
    "                            self.TOKENS.sent_str = self.TOKENS.sent_str.str.replace(r\"-\", ' ')\n",
    "                        if self.strip_whitespace == True:\n",
    "                            self.TOKENS = self.TOKENS.sent_str\\\n",
    "                                    .apply(lambda x: pd.Series(\n",
    "                                            nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)),\n",
    "                                            dtype='object'\n",
    "                                        )\n",
    "                                    )\n",
    "                        else:\n",
    "                            self.TOKENS = self.TOKENS.sent_str\\\n",
    "                                    .apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x))))\n",
    "                        self.TOKENS = self.TOKENS.stack().to_frame('pos_tuple')\n",
    "                        self.TOKENS['pos'] = self.TOKENS.pos_tuple.apply(lambda x: x[1])\n",
    "                        self.TOKENS['token_str'] = self.TOKENS.pos_tuple.apply(lambda x: x[0])\n",
    "                        self.TOKENS['term_str'] = self.TOKENS.token_str.str.lower()   \n",
    "        \n",
    "                else:\n",
    "                    raise ValueError(f\"Invalid parse option: {parse_type}.\")\n",
    "\n",
    "                # After creating the current OHCO level\n",
    "                self.TOKENS.index.names = self.OHCO[:i+1]\n",
    "\n",
    "            # After iterating through the OHCO\n",
    "\n",
    "            if not self.use_nltk:\n",
    "                self.TOKENS['term_str'] = self.TOKENS.token_str.str.replace(r'[\\W_]+', '', regex=True).str.lower()  \n",
    "            else:\n",
    "                punc_pos = ['$', \"''\", '(', ')', ',', '--', '.', ':', '``']\n",
    "                self.TOKENS['term_str'] = self.TOKENS[~self.TOKENS.pos.isin(punc_pos)].token_str\\\n",
    "                    .str.replace(r'[\\W_]+', '', regex=True).str.lower()  \n",
    "            \n",
    "        else:\n",
    "            raise RuntimeError(\"Source not imported. Please run .import_source()\")\n",
    "\n",
    "    def extract_vocab(self):\n",
    "        \"\"\"This should also be done at the corpus level.\"\"\"\n",
    "        self.VOCAB = self.TOKENS.term_str.value_counts().to_frame('n')\n",
    "        self.VOCAB.index.name = 'term_str'\n",
    "        self.VOCAB['n_chars'] = self.VOCAB.index.str.len()\n",
    "        self.VOCAB['p'] = self.VOCAB['n'] / self.VOCAB['n'].sum()\n",
    "        self.VOCAB['s'] = 1 / self.VOCAB['p']\n",
    "        self.VOCAB['i'] = np.log2(self.VOCAB['s']) # Same as negative log probability (i.e. log likelihood)\n",
    "        self.VOCAB['h'] = self.VOCAB['p'] * self.VOCAB['i']\n",
    "        self.H = self.VOCAB['h'].sum()\n",
    "        return self\n",
    "\n",
    "    def annotate_vocab(self):\n",
    "        \"\"\"This should be done at the corpus level.\"\"\"\n",
    "        # Stopwords\n",
    "        # Max POS\n",
    "        # POS variability\n",
    "        # Porter Stems\n",
    "        pass\n",
    "\n",
    "    def extract_pos_data(self):\n",
    "        # TODO: Create dataframe for POS info, including Penn Treebank info\n",
    "        pass\n",
    "\n",
    "    def extract_named_entities(self):\n",
    "        # TODO: Create dataframe of named entities\n",
    "        pass\n",
    "\n",
    "    def gather_tokens(self, level=0, grouping_col='term_str', cat_sep=' '):\n",
    "        \"\"\"Gather tokens into strings for arbitrary OHCO level.\"\"\"\n",
    "        max_level = len(self.OHCO) - 2 # Can't gather tokens at the token level :)\n",
    "        if level > max_level:\n",
    "            raise ValueError(f\"Level {level} too high. Try between 0 and {max_level}\")\n",
    "        else:\n",
    "            level_name = self.OHCO[level].split('_')[0]\n",
    "            idx = self.TOKENS.index.names[:level+1]\n",
    "            return self.TOKENS.groupby(idx)[grouping_col].apply(lambda x: x.str.cat(sep=cat_sep))\\\n",
    "                .to_frame(f'{level_name}_str')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_pats = [\n",
    "    r\"\\*\\*\\*\\s*START OF\",\n",
    "    r\"\\*\\*\\*\\s*END OF\"\n",
    "]\n",
    "\n",
    "# All are 'chap'and 'm'\n",
    "roman = '[IVXLCM]+'\n",
    "caps = \"[A-Z';, -]+\"\n",
    "ohco_pat_list = [\n",
    "    (768,   rf\"(?i)^\\s*CHAPTER\\s+{roman}\\.?\\s*$\"),\n",
    "    (3070,   rf\"^Chapter\\s+\\d+$\"),\n",
    "    (1661,  rf\"^\\s*{roman}\\.\\s*$\"),\n",
    "    (345,   rf\"(?i)^\\s*CHAPTER\\s+{roman}\\.?\\s*$\"),\n",
    "    (4078,   rf\"(?i)^\\s*CHAPTER\\s+{roman}\\.?\\s*$\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file_list = sorted(glob(f\"{source_files}/*.*\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:\\\\Users\\\\Student\\\\Desktop\\\\DS5001\\\\data\\\\gothic\\\\BRONTE_EMILY_WURTHERING_HEIGHTS-pg768.txt',\n",
       " 'C:\\\\Users\\\\Student\\\\Desktop\\\\DS5001\\\\data\\\\gothic\\\\DOYLE_ARTHURCONAN_THE_ADVENTURES_OF_SHERLOCK_HOLMES-pg1661.txt',\n",
       " 'C:\\\\Users\\\\Student\\\\Desktop\\\\DS5001\\\\data\\\\gothic\\\\DOYLE_ARTHURCONAN_THE_HOUND_OF_BASKERVILLES-pg3070.txt',\n",
       " 'C:\\\\Users\\\\Student\\\\Desktop\\\\DS5001\\\\data\\\\gothic\\\\STOKER_BRAM_DRACULA-pg345.txt',\n",
       " 'C:\\\\Users\\\\Student\\\\Desktop\\\\DS5001\\\\data\\\\gothic\\\\WILDE_OSCAR_THE_PICTURE_OF_DORIAN_GRAY-pg4078.txt']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_data = []\n",
    "for source_file_path in source_file_list:\n",
    "    book_id = int(source_file_path.split('-')[-1].split('.')[0].replace('pg',''))\n",
    "    book_title = source_file_path.split('\\\\')[-1].split('-')[0].replace('_', ' ')\n",
    "    book_data.append((book_id, source_file_path, book_title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB = pd.DataFrame(book_data, columns=['book_id','source_file_path','raw_title'])\\\n",
    "    .set_index('book_id').sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>raw_title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...</td>\n",
       "      <td>STOKER BRAM DRACULA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...</td>\n",
       "      <td>BRONTE EMILY WURTHERING HEIGHTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE ARTHURCONAN THE ADVENTURES OF SHERLOCK H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE ARTHURCONAN THE HOUND OF BASKERVILLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...</td>\n",
       "      <td>WILDE OSCAR THE PICTURE OF DORIAN GRAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "345      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...   \n",
       "768      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...   \n",
       "1661     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "3070     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "4078     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...   \n",
       "\n",
       "                                                 raw_title  \n",
       "book_id                                                     \n",
       "345                                    STOKER BRAM DRACULA  \n",
       "768                        BRONTE EMILY WURTHERING HEIGHTS  \n",
       "1661     DOYLE ARTHURCONAN THE ADVENTURES OF SHERLOCK H...  \n",
       "3070           DOYLE ARTHURCONAN THE HOUND OF BASKERVILLES  \n",
       "4078                WILDE OSCAR THE PICTURE OF DORIAN GRAY  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    LIB['author'] = LIB.raw_title.apply(lambda x: ', '.join(x.split()[:2]))\n",
    "    LIB['title'] = LIB.raw_title.apply(lambda x: ' '.join(x.split()[2:]))\n",
    "    LIB = LIB.drop('raw_title', axis=1)\n",
    "except AttributeError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...</td>\n",
       "      <td>STOKER, BRAM</td>\n",
       "      <td>DRACULA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...</td>\n",
       "      <td>BRONTE, EMILY</td>\n",
       "      <td>WURTHERING HEIGHTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE ADVENTURES OF SHERLOCK HOLMES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE HOUND OF BASKERVILLES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...</td>\n",
       "      <td>WILDE, OSCAR</td>\n",
       "      <td>THE PICTURE OF DORIAN GRAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "345      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...   \n",
       "768      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...   \n",
       "1661     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "3070     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "4078     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...   \n",
       "\n",
       "                     author                              title  \n",
       "book_id                                                         \n",
       "345            STOKER, BRAM                            DRACULA  \n",
       "768           BRONTE, EMILY                 WURTHERING HEIGHTS  \n",
       "1661     DOYLE, ARTHURCONAN  THE ADVENTURES OF SHERLOCK HOLMES  \n",
       "3070     DOYLE, ARTHURCONAN          THE HOUND OF BASKERVILLES  \n",
       "4078           WILDE, OSCAR         THE PICTURE OF DORIAN GRAY  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['chap_regex'] = LIB.index.map(pd.Series({x[0]:x[1] for x in ohco_pat_list}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>chap_regex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...</td>\n",
       "      <td>STOKER, BRAM</td>\n",
       "      <td>DRACULA</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...</td>\n",
       "      <td>BRONTE, EMILY</td>\n",
       "      <td>WURTHERING HEIGHTS</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE ADVENTURES OF SHERLOCK HOLMES</td>\n",
       "      <td>^\\s*[IVXLCM]+\\.\\s*$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE HOUND OF BASKERVILLES</td>\n",
       "      <td>^Chapter\\s+\\d+$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...</td>\n",
       "      <td>WILDE, OSCAR</td>\n",
       "      <td>THE PICTURE OF DORIAN GRAY</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "345      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...   \n",
       "768      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...   \n",
       "1661     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "3070     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "4078     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...   \n",
       "\n",
       "                     author                              title  \\\n",
       "book_id                                                          \n",
       "345            STOKER, BRAM                            DRACULA   \n",
       "768           BRONTE, EMILY                 WURTHERING HEIGHTS   \n",
       "1661     DOYLE, ARTHURCONAN  THE ADVENTURES OF SHERLOCK HOLMES   \n",
       "3070     DOYLE, ARTHURCONAN          THE HOUND OF BASKERVILLES   \n",
       "4078           WILDE, OSCAR         THE PICTURE OF DORIAN GRAY   \n",
       "\n",
       "                                 chap_regex  \n",
       "book_id                                      \n",
       "345      (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$  \n",
       "768      (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$  \n",
       "1661                    ^\\s*[IVXLCM]+\\.\\s*$  \n",
       "3070                        ^Chapter\\s+\\d+$  \n",
       "4078     (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_collection(LIB):\n",
    "\n",
    "    clip_pats = [\n",
    "        r\"\\*\\*\\*\\s*START OF\",\n",
    "        r\"\\*\\*\\*\\s*END OF\"\n",
    "    ]\n",
    "\n",
    "    books = []\n",
    "    for book_id in LIB.index:\n",
    "\n",
    "        # Announce\n",
    "        print(\"Tokenizing\", book_id, LIB.loc[book_id].title)\n",
    "\n",
    "        # Define vars\n",
    "        chap_regex = LIB.loc[book_id].chap_regex\n",
    "        ohco_pats = [('chap', chap_regex, 'm')]\n",
    "        src_file_path = LIB.loc[book_id].source_file_path\n",
    "\n",
    "        # Create object\n",
    "        text = TextParser(src_file_path, ohco_pats=ohco_pats, clip_pats=clip_pats, use_nltk=True)\n",
    "\n",
    "        # Define parameters\n",
    "        text.verbose = True\n",
    "        text.strip_hyphens = True\n",
    "        text.strip_whitespace = True\n",
    "\n",
    "        # Parse\n",
    "        text.import_source().parse_tokens();\n",
    "       \n",
    "        # Name things\n",
    "        text.TOKENS['book_id'] = book_id\n",
    "        text.TOKENS = text.TOKENS.reset_index().set_index(['book_id'] + text.OHCO)\n",
    "\n",
    "        # Add to list\n",
    "        books.append(text.TOKENS)\n",
    "        \n",
    "    # Combine into a single dataframe\n",
    "    CORPUS = pd.concat(books).sort_index()\n",
    "\n",
    "    # Clean up\n",
    "    del(books)\n",
    "    del(text)\n",
    "        \n",
    "    print(\"Done\")\n",
    "        \n",
    "    return CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(?i)^\\\\s*CHAPTER\\\\s+[IVXLCM]+\\\\.?\\\\s*$'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.loc[345].chap_regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing 345 DRACULA\n",
      "Importing  C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\STOKER_BRAM_DRACULA-pg345.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 768 WURTHERING HEIGHTS\n",
      "Importing  C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BRONTE_EMILY_WURTHERING_HEIGHTS-pg768.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 1661 THE ADVENTURES OF SHERLOCK HOLMES\n",
      "Importing  C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DOYLE_ARTHURCONAN_THE_ADVENTURES_OF_SHERLOCK_HOLMES-pg1661.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^\\s*[IVXLCM]+\\.\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 3070 THE HOUND OF BASKERVILLES\n",
      "Importing  C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DOYLE_ARTHURCONAN_THE_HOUND_OF_BASKERVILLES-pg3070.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone ^Chapter\\s+\\d+$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Tokenizing 4078 THE PICTURE OF DORIAN GRAY\n",
      "Importing  C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WILDE_OSCAR_THE_PICTURE_OF_DORIAN_GRAY-pg4078.txt\n",
      "Clipping text\n",
      "Parsing OHCO level 0 chap_id by milestone (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$\n",
      "line_str chap_str\n",
      "Index(['chap_str'], dtype='object')\n",
      "Parsing OHCO level 1 para_num by delimitter \\n\\n\n",
      "Parsing OHCO level 2 sent_num by NLTK model\n",
      "Parsing OHCO level 3 token_num by NLTK model\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "CORPUS = tokenize_collection(LIB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['book_len'] = CORPUS.groupby('book_id').term_str.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>book_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE HOUND OF BASKERVILLES</td>\n",
       "      <td>^Chapter\\s+\\d+$</td>\n",
       "      <td>59561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...</td>\n",
       "      <td>WILDE, OSCAR</td>\n",
       "      <td>THE PICTURE OF DORIAN GRAY</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "      <td>79446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE ADVENTURES OF SHERLOCK HOLMES</td>\n",
       "      <td>^\\s*[IVXLCM]+\\.\\s*$</td>\n",
       "      <td>105136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...</td>\n",
       "      <td>BRONTE, EMILY</td>\n",
       "      <td>WURTHERING HEIGHTS</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "      <td>116441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...</td>\n",
       "      <td>STOKER, BRAM</td>\n",
       "      <td>DRACULA</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "      <td>162859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "3070     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "4078     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...   \n",
       "1661     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "768      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...   \n",
       "345      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...   \n",
       "\n",
       "                     author                              title  \\\n",
       "book_id                                                          \n",
       "3070     DOYLE, ARTHURCONAN          THE HOUND OF BASKERVILLES   \n",
       "4078           WILDE, OSCAR         THE PICTURE OF DORIAN GRAY   \n",
       "1661     DOYLE, ARTHURCONAN  THE ADVENTURES OF SHERLOCK HOLMES   \n",
       "768           BRONTE, EMILY                 WURTHERING HEIGHTS   \n",
       "345            STOKER, BRAM                            DRACULA   \n",
       "\n",
       "                                 chap_regex  book_len  \n",
       "book_id                                                \n",
       "3070                        ^Chapter\\s+\\d+$     59561  \n",
       "4078     (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$     79446  \n",
       "1661                    ^\\s*[IVXLCM]+\\.\\s*$    105136  \n",
       "768      (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$    116441  \n",
       "345      (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$    162859  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.sort_values('book_len')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB['n_chaps'] = CORPUS.reset_index()[['book_id','chap_id']]\\\n",
    "    .drop_duplicates()\\\n",
    "    .groupby('book_id').chap_id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source_file_path</th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>chap_regex</th>\n",
       "      <th>book_len</th>\n",
       "      <th>n_chaps</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...</td>\n",
       "      <td>STOKER, BRAM</td>\n",
       "      <td>DRACULA</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "      <td>162859</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>768</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...</td>\n",
       "      <td>BRONTE, EMILY</td>\n",
       "      <td>WURTHERING HEIGHTS</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "      <td>116441</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1661</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE ADVENTURES OF SHERLOCK HOLMES</td>\n",
       "      <td>^\\s*[IVXLCM]+\\.\\s*$</td>\n",
       "      <td>105136</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3070</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...</td>\n",
       "      <td>DOYLE, ARTHURCONAN</td>\n",
       "      <td>THE HOUND OF BASKERVILLES</td>\n",
       "      <td>^Chapter\\s+\\d+$</td>\n",
       "      <td>59561</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...</td>\n",
       "      <td>WILDE, OSCAR</td>\n",
       "      <td>THE PICTURE OF DORIAN GRAY</td>\n",
       "      <td>(?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$</td>\n",
       "      <td>79446</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          source_file_path  \\\n",
       "book_id                                                      \n",
       "345      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\ST...   \n",
       "768      C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\BR...   \n",
       "1661     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "3070     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\DO...   \n",
       "4078     C:\\Users\\Student\\Desktop\\DS5001\\data\\gothic\\WI...   \n",
       "\n",
       "                     author                              title  \\\n",
       "book_id                                                          \n",
       "345            STOKER, BRAM                            DRACULA   \n",
       "768           BRONTE, EMILY                 WURTHERING HEIGHTS   \n",
       "1661     DOYLE, ARTHURCONAN  THE ADVENTURES OF SHERLOCK HOLMES   \n",
       "3070     DOYLE, ARTHURCONAN          THE HOUND OF BASKERVILLES   \n",
       "4078           WILDE, OSCAR         THE PICTURE OF DORIAN GRAY   \n",
       "\n",
       "                                 chap_regex  book_len  n_chaps  \n",
       "book_id                                                         \n",
       "345      (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$    162859       27  \n",
       "768      (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$    116441       34  \n",
       "1661                    ^\\s*[IVXLCM]+\\.\\s*$    105136        4  \n",
       "3070                        ^Chapter\\s+\\d+$     59561       15  \n",
       "4078     (?i)^\\s*CHAPTER\\s+[IVXLCM]+\\.?\\s*$     79446       21  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>book_len</th>\n",
       "      <th>n_chaps</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>104688.6</td>\n",
       "      <td>20.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>523443.0</td>\n",
       "      <td>101.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      book_len  n_chaps\n",
       "mean  104688.6     20.2\n",
       "sum   523443.0    101.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## handling anomalies\n",
    "LIB[['book_len', 'n_chaps']].agg(('mean','sum'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "*        707\n",
       "&         25\n",
       "£         25\n",
       "\"         19\n",
       "”         15\n",
       "...?”      2\n",
       "——         2\n",
       "...”       1\n",
       "”;         1\n",
       "?\"         1\n",
       "!”         1\n",
       "?”         1\n",
       "!\"         1\n",
       "Name: token_str, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS[CORPUS.term_str == ''].token_str.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS = CORPUS[CORPUS.term_str != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPUS['pos_group'] = CORPUS.pos.str[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>pos_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">345</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(JONATHAN, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>JONATHAN</td>\n",
       "      <td>jonathan</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(HARKER’S, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>HARKER’S</td>\n",
       "      <td>harkers</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(JOURNAL, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>JOURNAL</td>\n",
       "      <td>journal</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>((_Kept, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>(_Kept</td>\n",
       "      <td>kept</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(in, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4078</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">19</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>12</th>\n",
       "      <td>(who, WP)</td>\n",
       "      <td>WP</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(it, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(was., VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>was.</td>\n",
       "      <td>was</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(THE, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>THE</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(END, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>END</td>\n",
       "      <td>end</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522688 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos token_str  \\\n",
       "book_id chap_id para_num sent_num token_num                                   \n",
       "345     1       0        0        0          (JONATHAN, NNP)  NNP  JONATHAN   \n",
       "                                  1          (HARKER’S, NNP)  NNP  HARKER’S   \n",
       "                                  2           (JOURNAL, NNP)  NNP   JOURNAL   \n",
       "                1        0        0             ((_Kept, NN)   NN    (_Kept   \n",
       "                                  1                 (in, IN)   IN        in   \n",
       "...                                                      ...  ...       ...   \n",
       "4078    40      19       3        12               (who, WP)   WP       who   \n",
       "                                  13               (it, PRP)  PRP        it   \n",
       "                                  14             (was., VBD)  VBD      was.   \n",
       "                20       0        0                (THE, DT)   DT       THE   \n",
       "                                  1                (END, NN)   NN       END   \n",
       "\n",
       "                                             term_str pos_group  \n",
       "book_id chap_id para_num sent_num token_num                      \n",
       "345     1       0        0        0          jonathan        NN  \n",
       "                                  1           harkers        NN  \n",
       "                                  2           journal        NN  \n",
       "                1        0        0              kept        NN  \n",
       "                                  1                in        IN  \n",
       "...                                               ...       ...  \n",
       "4078    40      19       3        12              who        WP  \n",
       "                                  13               it        PR  \n",
       "                                  14              was        VB  \n",
       "                20       0        0               the        DT  \n",
       "                                  1               end        NN  \n",
       "\n",
       "[522688 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB = CORPUS.term_str.value_counts().to_frame('n').sort_index()\n",
    "VOCAB.index.name = 'term_str'\n",
    "VOCAB['n_chars'] = VOCAB.index.str.len()\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB['i'] = -np.log2(VOCAB.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>14.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16.188109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>17.410501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>15.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>16.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æt</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ætat</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>édition</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>émaux</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           n  n_chars         p          i\n",
       "term_str                                  \n",
       "1         16        1  0.000031  14.995464\n",
       "10         7        2  0.000013  16.188109\n",
       "100        3        3  0.000006  17.410501\n",
       "1000       8        4  0.000015  15.995464\n",
       "1018       1        4  0.000002  18.995464\n",
       "...       ..      ...       ...        ...\n",
       "à          4        1  0.000008  16.995464\n",
       "æt         1        2  0.000002  18.995464\n",
       "ætat       1        4  0.000002  18.995464\n",
       "édition    1        7  0.000002  18.995464\n",
       "émaux      1        5  0.000002  18.995464\n",
       "\n",
       "[19990 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotate Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['max_pos'] = CORPUS[['term_str','pos']].value_counts().unstack(fill_value=0).idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['max_pos_group'] = CORPUS[['term_str','pos_group']].value_counts().unstack(fill_value=0).idxmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>14.995464</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16.188109</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>17.410501</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>15.995464</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>16.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æt</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ætat</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>édition</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>émaux</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           n  n_chars         p          i max_pos max_pos_group\n",
       "term_str                                                        \n",
       "1         16        1  0.000031  14.995464      JJ            JJ\n",
       "10         7        2  0.000013  16.188109      JJ            JJ\n",
       "100        3        3  0.000006  17.410501      CD            CD\n",
       "1000       8        4  0.000015  15.995464      CD            CD\n",
       "1018       1        4  0.000002  18.995464      CD            CD\n",
       "...       ..      ...       ...        ...     ...           ...\n",
       "à          4        1  0.000008  16.995464      NN            NN\n",
       "æt         1        2  0.000002  18.995464      NN            NN\n",
       "ætat       1        4  0.000002  18.995464     NNP            NN\n",
       "édition    1        7  0.000002  18.995464      NN            NN\n",
       "émaux      1        5  0.000002  18.995464     NNP            NN\n",
       "\n",
       "[19990 rows x 6 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB['stop'] = VOCAB.index.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.apply(lambda x: stemmer1.stem(x.name), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>14.995464</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16.188109</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>17.410501</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>15.995464</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>16.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>à</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æt</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>æt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ætat</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>ætat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>édition</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>édition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>émaux</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>émaux</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           n  n_chars         p          i max_pos max_pos_group  stop  \\\n",
       "term_str                                                                 \n",
       "1         16        1  0.000031  14.995464      JJ            JJ     0   \n",
       "10         7        2  0.000013  16.188109      JJ            JJ     0   \n",
       "100        3        3  0.000006  17.410501      CD            CD     0   \n",
       "1000       8        4  0.000015  15.995464      CD            CD     0   \n",
       "1018       1        4  0.000002  18.995464      CD            CD     0   \n",
       "...       ..      ...       ...        ...     ...           ...   ...   \n",
       "à          4        1  0.000008  16.995464      NN            NN     0   \n",
       "æt         1        2  0.000002  18.995464      NN            NN     0   \n",
       "ætat       1        4  0.000002  18.995464     NNP            NN     0   \n",
       "édition    1        7  0.000002  18.995464      NN            NN     0   \n",
       "émaux      1        5  0.000002  18.995464     NNP            NN     0   \n",
       "\n",
       "         stem_porter  \n",
       "term_str              \n",
       "1                  1  \n",
       "10                10  \n",
       "100              100  \n",
       "1000            1000  \n",
       "1018            1018  \n",
       "...              ...  \n",
       "à                  à  \n",
       "æt                æt  \n",
       "ætat            ætat  \n",
       "édition      édition  \n",
       "émaux          émaux  \n",
       "\n",
       "[19990 rows x 8 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding DFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_BOW(CORPUS, bag):\n",
    "    \n",
    "    BOW = CORPUS.groupby(bags[bag]+['term_str']).term_str.count().to_frame('n')\n",
    "\n",
    "    return BOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['book_id','chap_id','para_num', 'sent_num', 'token_num']\n",
    "bags = dict(\n",
    "    SENTS = OHCO[:4],\n",
    "    PARAS = OHCO[:3],\n",
    "    CHAPS = OHCO[:2],\n",
    "    BOOKS = OHCO[:1]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "chaps = generate_BOW(CORPUS, 'CHAPS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">345</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th>13000</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1st</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4078</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th>yielded</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>you</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>young</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>your</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>youth</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125153 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          n\n",
       "book_id chap_id term_str   \n",
       "345     1       13000     1\n",
       "                1st       1\n",
       "                3         1\n",
       "                4         1\n",
       "                5         1\n",
       "...                      ..\n",
       "4078    40      yielded   1\n",
       "                you       1\n",
       "                young     2\n",
       "                your      1\n",
       "                youth     6\n",
       "\n",
       "[125153 rows x 1 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_dfidf(BOW):\n",
    "   \n",
    "    DTCM = BOW.n.unstack(fill_value=0)\n",
    "    \n",
    "    DF = DTCM.astype('bool').sum() \n",
    "    \n",
    "    N = DTCM.shape[0]\n",
    "    \n",
    "    IDF = np.log2(N / DF)\n",
    "    \n",
    "    DFIDF = DF * IDF\n",
    "    dfidf = pd.DataFrame(DFIDF).T\n",
    "    \n",
    "    return dfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_dfidf(chaps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31.394578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>24.439494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>18.632846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æt</th>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ætat</th>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>édition</th>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>émaux</th>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "term_str           \n",
       "1         31.394578\n",
       "10        24.439494\n",
       "100        6.658211\n",
       "1000       6.658211\n",
       "1018       6.658211\n",
       "...             ...\n",
       "à         18.632846\n",
       "æt         6.658211\n",
       "ætat       6.658211\n",
       "édition    6.658211\n",
       "émaux      6.658211\n",
       "\n",
       "[19990 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.transpose()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "columns overlap but no suffix specified: Index([0], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-41a6c26ec3ca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mVOCAB\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVOCAB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   7868\u001b[0m         \u001b[1;36m5\u001b[0m  \u001b[0mK5\u001b[0m  \u001b[0mA5\u001b[0m  \u001b[0mNaN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7869\u001b[0m         \"\"\"\n\u001b[1;32m-> 7870\u001b[1;33m         return self._join_compat(\n\u001b[0m\u001b[0;32m   7871\u001b[0m             \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mrsuffix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7872\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_join_compat\u001b[1;34m(self, other, on, how, lsuffix, rsuffix, sort)\u001b[0m\n\u001b[0;32m   7884\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7885\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7886\u001b[1;33m             return merge(\n\u001b[0m\u001b[0;32m   7887\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7888\u001b[0m                 \u001b[0mother\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     87\u001b[0m         \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     )\n\u001b[1;32m---> 89\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    668\u001b[0m         \u001b[0mjoin_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleft_indexer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mright_indexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_join_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 670\u001b[1;33m         llabels, rlabels = _items_overlap_with_suffix(\n\u001b[0m\u001b[0;32m    671\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mleft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2089\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2090\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mlsuffix\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mrsuffix\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2091\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"columns overlap but no suffix specified: {to_rename}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2092\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2093\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrenamer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msuffix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: columns overlap but no suffix specified: Index([0], dtype='object')"
     ]
    }
   ],
   "source": [
    "VOCAB = VOCAB.join(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.rename(columns={0: 'dfidf'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>dfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>14.995464</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.394578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>16.188109</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>24.439494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>17.410501</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>15.995464</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>CD</td>\n",
       "      <td>CD</td>\n",
       "      <td>0</td>\n",
       "      <td>1018</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>à</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>16.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>à</td>\n",
       "      <td>18.632846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>æt</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>æt</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ætat</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>ætat</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>édition</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>édition</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>émaux</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>18.995464</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>émaux</td>\n",
       "      <td>6.658211</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19990 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           n  n_chars         p          i max_pos max_pos_group  stop  \\\n",
       "term_str                                                                 \n",
       "1         16        1  0.000031  14.995464      JJ            JJ     0   \n",
       "10         7        2  0.000013  16.188109      JJ            JJ     0   \n",
       "100        3        3  0.000006  17.410501      CD            CD     0   \n",
       "1000       8        4  0.000015  15.995464      CD            CD     0   \n",
       "1018       1        4  0.000002  18.995464      CD            CD     0   \n",
       "...       ..      ...       ...        ...     ...           ...   ...   \n",
       "à          4        1  0.000008  16.995464      NN            NN     0   \n",
       "æt         1        2  0.000002  18.995464      NN            NN     0   \n",
       "ætat       1        4  0.000002  18.995464     NNP            NN     0   \n",
       "édition    1        7  0.000002  18.995464      NN            NN     0   \n",
       "émaux      1        5  0.000002  18.995464     NNP            NN     0   \n",
       "\n",
       "         stem_porter      dfidf  \n",
       "term_str                         \n",
       "1                  1  31.394578  \n",
       "10                10  24.439494  \n",
       "100              100   6.658211  \n",
       "1000            1000   6.658211  \n",
       "1018            1018   6.658211  \n",
       "...              ...        ...  \n",
       "à                  à  18.632846  \n",
       "æt                æt   6.658211  \n",
       "ætat            ætat   6.658211  \n",
       "édition      édition   6.658211  \n",
       "émaux          émaux   6.658211  \n",
       "\n",
       "[19990 rows x 9 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20 Most Significant Words by DFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>n_chars</th>\n",
       "      <th>p</th>\n",
       "      <th>i</th>\n",
       "      <th>max_pos</th>\n",
       "      <th>max_pos_group</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>dfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_str</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wonderful</th>\n",
       "      <td>95</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>12.425608</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>wonder</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reach</th>\n",
       "      <td>56</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000107</td>\n",
       "      <td>13.188109</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>reach</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>promise</th>\n",
       "      <td>81</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>12.655614</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>promis</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serious</th>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>12.951069</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>seriou</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brain</th>\n",
       "      <td>93</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>12.456305</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>brain</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>street</th>\n",
       "      <td>150</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000287</td>\n",
       "      <td>11.766645</td>\n",
       "      <td>NNP</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>street</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>telling</th>\n",
       "      <td>58</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>13.137483</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>tell</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creature</th>\n",
       "      <td>66</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>12.951069</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>creatur</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seized</th>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>13.240576</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>seiz</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>son</th>\n",
       "      <td>123</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>12.052949</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>son</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>view</th>\n",
       "      <td>59</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>13.112820</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>view</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>following</th>\n",
       "      <td>51</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>13.323038</td>\n",
       "      <td>VBG</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>follow</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>123</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000235</td>\n",
       "      <td>12.052949</td>\n",
       "      <td>NNS</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>women</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fall</th>\n",
       "      <td>61</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000117</td>\n",
       "      <td>13.064726</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>fall</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>remembered</th>\n",
       "      <td>53</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>13.267543</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>rememb</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hurt</th>\n",
       "      <td>55</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>13.214104</td>\n",
       "      <td>VB</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>hurt</td>\n",
       "      <td>53.604050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>study</th>\n",
       "      <td>73</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>12.805639</td>\n",
       "      <td>NN</td>\n",
       "      <td>NN</td>\n",
       "      <td>0</td>\n",
       "      <td>studi</td>\n",
       "      <td>53.590791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>curious</th>\n",
       "      <td>88</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>12.536032</td>\n",
       "      <td>JJ</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0</td>\n",
       "      <td>curiou</td>\n",
       "      <td>53.590791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>become</th>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>12.747536</td>\n",
       "      <td>VBN</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>becom</td>\n",
       "      <td>53.590791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covered</th>\n",
       "      <td>62</td>\n",
       "      <td>7</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>13.041267</td>\n",
       "      <td>VBD</td>\n",
       "      <td>VB</td>\n",
       "      <td>0</td>\n",
       "      <td>cover</td>\n",
       "      <td>53.590791</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              n  n_chars         p          i max_pos max_pos_group  stop  \\\n",
       "term_str                                                                    \n",
       "wonderful    95        9  0.000182  12.425608      JJ            JJ     0   \n",
       "reach        56        5  0.000107  13.188109      VB            VB     0   \n",
       "promise      81        7  0.000155  12.655614      NN            NN     0   \n",
       "serious      66        7  0.000126  12.951069      JJ            JJ     0   \n",
       "brain        93        5  0.000178  12.456305      NN            NN     0   \n",
       "street      150        6  0.000287  11.766645     NNP            NN     0   \n",
       "telling      58        7  0.000111  13.137483     VBG            VB     0   \n",
       "creature     66        8  0.000126  12.951069      NN            NN     0   \n",
       "seized       54        6  0.000103  13.240576     VBD            VB     0   \n",
       "son         123        3  0.000235  12.052949      NN            NN     0   \n",
       "view         59        4  0.000113  13.112820      NN            NN     0   \n",
       "following    51        9  0.000098  13.323038     VBG            VB     0   \n",
       "women       123        5  0.000235  12.052949     NNS            NN     0   \n",
       "fall         61        4  0.000117  13.064726      VB            VB     0   \n",
       "remembered   53       10  0.000101  13.267543     VBD            VB     0   \n",
       "hurt         55        4  0.000105  13.214104      VB            VB     0   \n",
       "study        73        5  0.000140  12.805639      NN            NN     0   \n",
       "curious      88        7  0.000168  12.536032      JJ            JJ     0   \n",
       "become       76        6  0.000145  12.747536     VBN            VB     0   \n",
       "covered      62        7  0.000119  13.041267     VBD            VB     0   \n",
       "\n",
       "           stem_porter      dfidf  \n",
       "term_str                           \n",
       "wonderful       wonder  53.604050  \n",
       "reach            reach  53.604050  \n",
       "promise         promis  53.604050  \n",
       "serious         seriou  53.604050  \n",
       "brain            brain  53.604050  \n",
       "street          street  53.604050  \n",
       "telling           tell  53.604050  \n",
       "creature       creatur  53.604050  \n",
       "seized            seiz  53.604050  \n",
       "son                son  53.604050  \n",
       "view              view  53.604050  \n",
       "following       follow  53.604050  \n",
       "women            women  53.604050  \n",
       "fall              fall  53.604050  \n",
       "remembered      rememb  53.604050  \n",
       "hurt              hurt  53.604050  \n",
       "study            studi  53.590791  \n",
       "curious         curiou  53.590791  \n",
       "become           becom  53.590791  \n",
       "covered          cover  53.590791  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sort_values('dfidf', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## exporting corpus, vocab and lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.ConfigParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.read(\"../../../env.ini\")\n",
    "data_home = config['DEFAULT']['data_home']\n",
    "output_dir = config['DEFAULT']['output_dir']\n",
    "local_lib = config['DEFAULT']['local_lib']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_prefix = 'gothic-texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f'{output_dir}/{data_prefix}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>pos_group</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>book_id</th>\n",
       "      <th>chap_id</th>\n",
       "      <th>para_num</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">345</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(JONATHAN, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>JONATHAN</td>\n",
       "      <td>jonathan</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(HARKER’S, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>HARKER’S</td>\n",
       "      <td>harkers</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(JOURNAL, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>JOURNAL</td>\n",
       "      <td>journal</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>((_Kept, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>(_Kept</td>\n",
       "      <td>kept</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(in, IN)</td>\n",
       "      <td>IN</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">4078</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">40</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">19</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">3</th>\n",
       "      <th>12</th>\n",
       "      <td>(who, WP)</td>\n",
       "      <td>WP</td>\n",
       "      <td>who</td>\n",
       "      <td>who</td>\n",
       "      <td>WP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>(it, PRP)</td>\n",
       "      <td>PRP</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "      <td>PR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>(was., VBD)</td>\n",
       "      <td>VBD</td>\n",
       "      <td>was.</td>\n",
       "      <td>was</td>\n",
       "      <td>VB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">20</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(THE, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>THE</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(END, NN)</td>\n",
       "      <td>NN</td>\n",
       "      <td>END</td>\n",
       "      <td>end</td>\n",
       "      <td>NN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>522688 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   pos_tuple  pos token_str  \\\n",
       "book_id chap_id para_num sent_num token_num                                   \n",
       "345     1       0        0        0          (JONATHAN, NNP)  NNP  JONATHAN   \n",
       "                                  1          (HARKER’S, NNP)  NNP  HARKER’S   \n",
       "                                  2           (JOURNAL, NNP)  NNP   JOURNAL   \n",
       "                1        0        0             ((_Kept, NN)   NN    (_Kept   \n",
       "                                  1                 (in, IN)   IN        in   \n",
       "...                                                      ...  ...       ...   \n",
       "4078    40      19       3        12               (who, WP)   WP       who   \n",
       "                                  13               (it, PRP)  PRP        it   \n",
       "                                  14             (was., VBD)  VBD      was.   \n",
       "                20       0        0                (THE, DT)   DT       THE   \n",
       "                                  1                (END, NN)   NN       END   \n",
       "\n",
       "                                             term_str pos_group  \n",
       "book_id chap_id para_num sent_num token_num                      \n",
       "345     1       0        0        0          jonathan        NN  \n",
       "                                  1           harkers        NN  \n",
       "                                  2           journal        NN  \n",
       "                1        0        0              kept        NN  \n",
       "                                  1                in        IN  \n",
       "...                                               ...       ...  \n",
       "4078    40      19       3        12              who        WP  \n",
       "                                  13               it        PR  \n",
       "                                  14              was        VB  \n",
       "                20       0        0               the        DT  \n",
       "                                  1               end        NN  \n",
       "\n",
       "[522688 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB.to_csv(f'{out_path}-LIB.csv')\n",
    "VOCAB.to_csv(f'{out_path}-VOCAB.csv')\n",
    "CORPUS.to_csv(f'{out_path}-CORPUS.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
